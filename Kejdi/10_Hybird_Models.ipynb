{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Methods for Glacier Flow\n",
    "\n",
    "## 1. Introduction to Glacier Flow\n",
    "Glaciers are massive bodies of ice that flow slowly under their own weight. The flow of ice in a glacier is a complex process governed by physical laws that describe how the ice deforms and moves.\n",
    "Given an initial glacier geometry, the time evolution in ice thickness $h(x, y, t)$ is determined by the mass conservation equation, which couples ice dynamics and surface mass balance (SMB)\n",
    "through: \n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "    \\frac{\\partial h}{\\partial t} + \\nabla \\cdot (\\mathbf{u}h) = SMB,\n",
    "     \\\\\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "where $\\nabla \\cdot$ denotes the divergence operator with respect to the flux ($Q=\\mathbf{u}h$). $\\mathbf{u}$ is the vertically averaged horizontal ice velocity field and SMB the SMB function, which consists of the\n",
    "integration of ice accumulation and ablation over one year. Mass conservation equation is generic and can be applied to model glacier evolution in number of applications provided adequate SMB and ice-flow model components. \n",
    "In the following, we mostly focus on developing an efficient numerical method to compute the ice-flow considering it is often the most computationally expensive component in glacier evolution model.\n",
    "\n",
    "- First, we will use a numerical solution to compute $Q$. \n",
    "- Then we will use a data-driven Machine Learning (ML) approach that emulates ice-flow (Jouvet and others, 2022). \n",
    "The state of the art ML techniques ( Jouvet and Cordonnier, 2023), use a Physics Informed Neural Network (PINN); however, this goes beyond the scope of this chapter which focuses on hybrid models.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Glen-Stokes Equations\n",
    "The **Glen-Stokes model** is a widely used theoretical framework to describe this flow, particularly in the context of ice dynamics.\n",
    "\n",
    "### 2.1 Stokes Equations for Glacier Flow\n",
    "The Stokes equations are fundamental to describing the motion of viscous fluids, including glacier ice. For glaciers, the flow is generally assumed to be slow enough that inertial forces can be neglected, leaving us with the simplified Stokes equations:\n",
    "\n",
    "$\n",
    "\\begin{aligned}\n",
    "    -\\nabla \\cdot \\sigma &= \\rho \\mathbf{g}, \\\\\n",
    "    \\nabla \\cdot \\mathbf{u} &= 0.\n",
    "\\end{aligned}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $\\sigma$ is the Cauchy stress tensor, which represents internal stresses within the glacier ice.\n",
    "- $\\rho$ is the density of ice (about 910 kg/m³).\n",
    "- $\\mathbf{g}$ is the gravitational acceleration vector.\n",
    "- $\\mathbf{u}$ is the velocity vector of the ice.\n",
    "\n",
    "### 2.2 Glen's Flow Law\n",
    "Glen's flow law relates the strain rate (deformation rate) of the ice to the applied stress. This relationship is crucial for understanding how ice deforms under pressure and is given by:\n",
    "\n",
    "$\n",
    "\\mathbf{D}(\\mathbf{u}) = \\frac{1}{2} (\\nabla \\mathbf{u} + \\nabla \\mathbf{u}^\\top)\n",
    "$\n",
    "\n",
    "The stress-strain relationship, often called Glen's law, is expressed as:\n",
    "\n",
    "$\n",
    "\\mathbf{\\tau} = 2\\eta \\mathbf{D}(\\mathbf{u}),\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{\\tau}$ is the deviatoric stress tensor (a measure of stress causing deformation).\n",
    "- $\\eta$ is the effective viscosity of ice, which depends on the temperature and the stress applied to the ice.\n",
    "- $\\mathbf{D}(\\mathbf{u})$ is the strain rate tensor.\n",
    "\n",
    "Glen's law is non-linear and can be expressed in the following form:\n",
    "\n",
    "$\n",
    "\\mathbf{\\tau} = 2 A^{-1/n} \\left|\\mathbf{D}(\\mathbf{u})\\right|^{\\frac{1-n}{n}} \\mathbf{D}(\\mathbf{u}),\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $A$ is the flow rate factor, dependent on temperature.\n",
    "- $n$ is Glen’s exponent, typically taken as 3 for glacier ice, indicating the non-linear relationship between stress and strain rate.\n",
    "- $\\left|\\mathbf{D}(\\mathbf{u})\\right|$ is the magnitude of the strain rate tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Transition to the Ice Sheet Equation\n",
    "\n",
    "The Glen-Stokes equations describe the flow of ice under stress, but their computational cost makes them impractical for large-scale ice-sheet modeling over long time periods. This leads us to introduce the **shallow ice approximation (SIA)**, which is used in ice sheet models due to its simplicity and efficiency.\n",
    "\n",
    "The SIA simplifies the full Stokes equations by assuming that the ice flow is dominated by vertical shear stresses and that horizontal stresses can be neglected. This results in an expression for the ice velocity in terms of the ice thickness gradient and the surface slope. The ice velocity $\\mathbf{u}$ can be approximated as:\n",
    "\n",
    "$\n",
    "\\mathbf{u} = -\\left(\\frac{2 A}{n+2}\\right) \\left(\\rho g \\sin(s)\\right)^n h^{n+1} \\nabla h,\n",
    "$\n",
    "\n",
    "where:\n",
    "- $\\rho$ is the ice density,\n",
    "- $g$ is the gravitational acceleration,\n",
    "- $A$ is Glen's flow rate factor,\n",
    "- $n$ is Glen's law exponent (typically 3),\n",
    "- $h$ is the ice thickness, and\n",
    "- $s$ is the surface slope.\n",
    "\n",
    "This equation governs the horizontal velocity of ice based on the local ice thickness and slope, and is more computationally feasible than the full Glen-Stokes model.\n",
    "We plug the **u** into the mass conservation equation and obtain: \n",
    "\n",
    "$\n",
    "\\frac{\\partial h}{\\partial t} + \\nabla \\cdot (D(h,z)\\frac{\\partial z}{\\partial x}) = \\text{SMB},\n",
    "$\n",
    "\n",
    "where $D(h,z) =  f_d (\\rho g)^3 h^5 |\\nabla S|^2$.\n",
    "\n",
    "This equation describes the time evolution of the ice thickness, where the velocity $\\mathbf{u}$ is computed from the ice sheet's surface slope and thickness. This approach provides a balance between accuracy and computational efficiency and is widely used in large-scale ice sheet models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Boundary Conditions\n",
    "\n",
    "### 3.1 No-Slip Condition at the Base\n",
    "In many glacier models, we assume a no-slip condition at the base, meaning the ice velocity is zero at the bedrock. This condition is suitable for glaciers frozen to their beds:\n",
    "\n",
    "$\n",
    "\\mathbf{u} = 0 \\text{ on the bedrock surface}.\n",
    "$\n",
    "\n",
    "### 3.2 Stress-Free Surface\n",
    "At the glacier surface (exposed to air), a stress-free boundary condition is typically applied:\n",
    "\n",
    "$\n",
    "\\sigma \\cdot \\mathbf{n} = 0 \\text{ on the surface},\n",
    "$\n",
    "\n",
    "Where $\\mathbf{n}$ is the outward normal vector at the glacier surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy import ndimage\n",
    "import netCDF4\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical parameters\n",
    "Lx = 49700    # Domain length in x (m)\n",
    "Ly = 32300    # Domain length in y (m)\n",
    "ttot = 700   # Time limit (yr)\n",
    "grad_b = 0.001 # Mass balance gradient (no unit)\n",
    "b_max = 0.5   # Maximum precip (m/yr)\n",
    "Z_ELA = 3000  # Elevation of equilibrium line altitude (m)\n",
    "rho = 910.0   # Ice density (g/m^3)\n",
    "g   = 9.81    # Earth's gravity (m/s^2)\n",
    "fd  = 1e-18   # Deformation constant (Pa^-3 y^-1) \n",
    "\n",
    "\n",
    "\n",
    "# Initialization & load data\n",
    "\n",
    "nout = 50  # Frequency of plotting\n",
    "dtmax = 1   # maximum time step\n",
    "dt = dtmax  # Initial time step\n",
    "dx = 100\n",
    "dy = 100  # Cell size in y\n",
    "nx=int(Lx/dx)\n",
    "ny=int(Ly/dy)\n",
    "x = np.linspace(0, Lx, nx)  # x-coordinates\n",
    "y = np.linspace(0, Ly, ny)  # y-coordinates\n",
    "\n",
    "nc_file = netCDF4.Dataset('bedrock.nc')  # Load the NetCDF file\n",
    "Z_topo = nc_file.variables['topg']    # Replace 'topg' with the appropriate v\n",
    "\n",
    "H_ice = np.zeros((ny, nx))  # Initial ice thickness\n",
    "Z_surf = Z_topo + H_ice  # Initial ice surface\n",
    "time = 0  # Initial time\n",
    "it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop\n",
    "while time < ttot:\n",
    "    \n",
    "    # Update time\n",
    "    time += dt\n",
    "    it   += 1\n",
    "\n",
    "\n",
    "    # Calculate H_avg, size (ny-1,nx-1)\n",
    "    H_avg = 0.25 * (H_ice[:-1, :-1] + H_ice[1:, 1:] + H_ice[:-1, 1:] + H_ice[1:, :-1])\n",
    "\n",
    "\n",
    "    # Compute Snorm, size (ny-1,nx-1)\n",
    "    Sx = np.diff(Z_surf, axis=1) / dx\n",
    "    Sy = np.diff(Z_surf, axis=0) / dy\n",
    "    Sx = 0.5 * (Sx[:-1, :] + Sx[1:, :])\n",
    "    Sy = 0.5 * (Sy[:, :-1] + Sy[:, 1:])\n",
    "    Snorm = np.sqrt(Sx**2 + Sy**2)\n",
    "\n",
    "\n",
    "    # Compute D, size (ny-1,nx-1)\n",
    "    D = fd * (rho * g)**3.0 * H_avg**5 * Snorm**2\n",
    "\n",
    "\n",
    "    # Compute dt\n",
    "    dt = min(min(dx, dy)**2 / (4.1 * np.max(D)), dtmax)\n",
    "\n",
    "\n",
    "    # Compute qx, size (ny-2,nx-1)\n",
    "    qx = -(0.5 * (D[:-1,:] + D[1:,:])) * np.diff(Z_surf[1:-1,:], axis=1) / dx\n",
    "\n",
    "\n",
    "    # Compute qy, size (ny-1,nx-2)\n",
    "    qy = -(0.5 * (D[:,:-1] + D[:,1:])) * np.diff(Z_surf[:,1:-1,], axis=0) / dy\n",
    "\n",
    "\n",
    "    # Update rule (diffusion)\n",
    "    dHdt = -(np.diff(qx, axis=1) / dx + np.diff(qy, axis=0) / dy)\n",
    "    H_ice[1:-1, 1:-1] += dt * dHdt # size (ny-2,nx-2)\n",
    "\n",
    "\n",
    "    b = np.minimum(grad_b * (Z_surf - Z_ELA), b_max)\n",
    "\n",
    "\n",
    "    # Update rule (mass balance)\n",
    "    H_ice[1:-1, 1:-1] += dt * b[1:-1, 1:-1]\n",
    "\n",
    "\n",
    "    # Update rule (positive thickness)\n",
    "    H_ice = np.maximum(H_ice, 0)\n",
    "\n",
    "\n",
    "    # updatesurface topography\n",
    "    Z_surf = Z_topo + H_ice\n",
    "  \n",
    "    # Update ELA after 500 years\n",
    "    if time > 500:\n",
    "        Z_ELA = 2700\n",
    "\n",
    "    # Display\n",
    "    if it % nout == 0:\n",
    "        clear_output(wait=True)  # Clear the previous output in the notebook\n",
    "    \n",
    "        plt.figure(2, figsize=(11, 4), dpi=200)\n",
    "        \n",
    "        # First subplot: Ice surface\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(Z_surf, extent=[0, Lx/1000, 0, Ly/1000], cmap='terrain', origin='lower')\n",
    "        plt.colorbar(label='Elevation (m)')\n",
    "        plt.title('Ice Surface at ' + str(int(time)) + ' y')\n",
    "        plt.xlabel('Distance, km')\n",
    "        plt.ylabel('Distance, km')\n",
    "    \n",
    "        # Second subplot: Ice thickness\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(np.where(H_ice > 0, H_ice, np.nan), extent=[0, Lx/1000, 0, Ly/1000], cmap='jet', origin='lower')\n",
    "        plt.colorbar(label='Ice Thickness (m)')\n",
    "        plt.title('Ice Thickness at ' + str(int(time)) + ' y')\n",
    "        plt.xlabel('Distance, km')\n",
    "        plt.ylabel('Distance, km')\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Emulating Ice Flow with Machine Learning\n",
    "\n",
    "The *Instructed Glacier Model* (IGM) presented by Jouvet et al. introduces a convolutional neural network (CNN) to predict ice flow, trained using data from traditional models such as hybrid SIA+SSA or Stokes models. The advantage of this approach is that it substitutes the computationally expensive ice flow component with a much faster emulator. This enables simulations that are up to 1000 times faster, with a fidelity of over 90%.\n",
    "\n",
    "### 4.1 Overview of the Machine Learning Approach\n",
    "\n",
    "Machine learning, specifically deep learning, allows us to create surrogate models that emulate the glacier dynamics described by traditional models. These surrogate models, once trained, provide nearly identical ice flow solutions at a fraction of the computational cost.\n",
    "\n",
    "- **CNN Emulator**: A convolutional neural network (CNN) is trained on input data such as ice thickness, surface slope, and basal sliding coefficients, and it predicts the ice flow field (horizontal velocity).\n",
    "  \n",
    "- **Training**: The network is trained using data generated from physically accurate glacier models like PISM (Parallel Ice Sheet Model) or CfsFlow. This large dataset is crucial for high fidelity and ensuring the emulator can generalize across different glaciers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I suggest to use Tensor Flow variables instead of Numpy\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "train_mode=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load, merge NetCDF files, and fill NaN with 0\n",
    "def load_and_merge_netcdf(files):\n",
    "    datasets = [xr.open_dataset(file) for file in files]\n",
    "    \n",
    "    # Align the datasets along the spatial dimensions using fill_value=0 for NaN\n",
    "    combined_ds = xr.concat(datasets, dim='time', join='outer').fillna(0)\n",
    "    \n",
    "    return combined_ds\n",
    "\n",
    "# Function to scale the field based on 90th percentile of its maximum\n",
    "def scale_field(field):\n",
    "    max_90th_percentile = np.percentile(field.max(axis=(1, 2)), 90)\n",
    "    return field / max_90th_percentile\n",
    "\n",
    "# Function to augment the data by flipping and adding noise\n",
    "def augment_data(inputs, outputs):\n",
    "    aug_inputs, aug_outputs = [], []\n",
    "\n",
    "    for inp, out in zip(inputs, outputs):\n",
    "        # Original data\n",
    "        aug_inputs.append(inp)\n",
    "        aug_outputs.append(out)\n",
    "\n",
    "        # Horizontal flip\n",
    "        aug_inputs.append(np.flip(inp, axis=2))  # Flip along x-axis\n",
    "        aug_outputs.append(np.flip(out, axis=2))\n",
    "\n",
    "        # Vertical flip\n",
    "        aug_inputs.append(np.flip(inp, axis=1))  # Flip along y-axis\n",
    "        aug_outputs.append(np.flip(out, axis=1))\n",
    "\n",
    "        # Add random Gaussian noise\n",
    "        noise_factor = 0.05\n",
    "        aug_inputs.append(inp + noise_factor * np.random.normal(size=inp.shape))\n",
    "        aug_outputs.append(out + noise_factor * np.random.normal(size=out.shape))\n",
    "\n",
    "    return np.array(aug_inputs), np.array(aug_outputs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot input and output fields side by side with color bars\n",
    "def plot_input_output(thk, slopesurx, slopesury, ubar, vbar):\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # Plot inputs\n",
    "    im0 = axs[0, 0].imshow(thk, cmap='Blues')\n",
    "    axs[0, 0].set_title('Ice Thickness (thk)')\n",
    "    axs[0, 0].set_xlabel('x')\n",
    "    axs[0, 0].set_ylabel('y')\n",
    "    fig.colorbar(im0, ax=axs[0, 0], orientation='vertical')\n",
    "\n",
    "    im1 = axs[0, 1].imshow(slopesurx, cmap='RdBu')\n",
    "    axs[0, 1].set_title('Surface Slope x (slopesurx)')\n",
    "    axs[0, 1].set_xlabel('x')\n",
    "    axs[0, 1].set_ylabel('y')\n",
    "    fig.colorbar(im1, ax=axs[0, 1], orientation='vertical')\n",
    "\n",
    "    im2 = axs[0, 2].imshow(slopesury, cmap='RdBu')\n",
    "    axs[0, 2].set_title('Surface Slope y (slopesury)')\n",
    "    axs[0, 2].set_xlabel('x')\n",
    "    axs[0, 2].set_ylabel('y')\n",
    "    fig.colorbar(im2, ax=axs[0, 2], orientation='vertical')\n",
    "\n",
    "    # Plot outputs\n",
    "    im3 = axs[1, 0].imshow(ubar, cmap='viridis')\n",
    "    axs[1, 0].set_title('Velocity x (ubar)')\n",
    "    axs[1, 0].set_xlabel('x')\n",
    "    axs[1, 0].set_ylabel('y')\n",
    "    fig.colorbar(im3, ax=axs[1, 0], orientation='vertical')\n",
    "\n",
    "    im4 = axs[1, 1].imshow(vbar, cmap='viridis')\n",
    "    axs[1, 1].set_title('Velocity y (vbar)')\n",
    "    axs[1, 1].set_xlabel('x')\n",
    "    axs[1, 1].set_ylabel('y')\n",
    "    fig.colorbar(im4, ax=axs[1, 1], orientation='vertical')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths (Replace with your actual file paths)\n",
    "file_paths = ['/home/klleshi/Desktop/surflib3d_A78_100/ALP11_A78_C0/ex.nc']\n",
    "\n",
    "# Load and merge the NetCDF datasets\n",
    "merged_data = load_and_merge_netcdf(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the input and output fields\n",
    "thk = merged_data['thk'].values           # Ice thickness\n",
    "slopsurfx = merged_data['slopsurfx'].values # Surface slope in x\n",
    "slopsurfy = merged_data['slopsurfy'].values # Surface slope in y\n",
    "ubar = merged_data['ubar'].values         # Velocity x component\n",
    "vbar = merged_data['vbar'].values         # Velocity y component\n",
    "usurf = merged_data['usurf'].values\n",
    "\n",
    "# Calculate 90th percentile scaling factors for training\n",
    "scaling_factors = {\n",
    "    \"thk\": np.percentile(thk.max(axis=(1, 2)), 90),\n",
    "    \"slopsurfx\": np.percentile(slopsurfx.max(axis=(1, 2)), 90),\n",
    "    \"slopsurfy\": np.percentile(slopsurfy.max(axis=(1, 2)), 90),\n",
    "    \"ubar\": np.percentile(ubar.max(axis=(1, 2)), 90),\n",
    "    \"vbar\": np.percentile(vbar.max(axis=(1, 2)), 90)\n",
    "}\n",
    "\n",
    "# Step 2: Scale each field using the 90th percentile of its maximum\n",
    "thk_scaled = scale_field(thk)\n",
    "slopsurfx_scaled = scale_field(slopsurfx)\n",
    "slopsurfy_scaled = scale_field(slopsurfy)\n",
    "ubar_scaled = scale_field(ubar)\n",
    "vbar_scaled = scale_field(vbar)\n",
    "usurf_scaled = scale_field(usurf)\n",
    "\n",
    "# Step 3: Stack inputs and outputs after scaling\n",
    "inputs_scaled = np.stack([thk_scaled, slopsurfx_scaled, slopsurfy_scaled], axis=-1)  # Shape: (time, y, x, 3)\n",
    "outputs_scaled = np.stack([ubar_scaled, vbar_scaled], axis=-1)  # Shape: (time, y, x, 2)\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Inputs scaled shape: {inputs_scaled.shape}\")\n",
    "print(f\"Outputs scaled shape: {outputs_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopsurfy_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data to visualize the relationship between input and output\n",
    "time_idx=20\n",
    "plot_input_output(thk[time_idx], slopsurfx[time_idx], slopsurfy[time_idx], ubar[time_idx], vbar[time_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start working on the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration as a dictionary\n",
    "config = {\n",
    "    \"nb_layers\": 4,               # Number of convolutional layers\n",
    "    \"nb_out_filter\": 32,           # Number of output filters for Conv2D\n",
    "    \"conv_ker_size\": 3,            # Convolution kernel size\n",
    "    \"activation\": \"relu\",          # Activation function: \"relu\" or \"lrelu\"\n",
    "    \"dropout_rate\": 0.1,           # Dropout rate\n",
    "    \"regularization\": 0.0001       # L2 regularization\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(nb_inputs, nb_outputs, config):\n",
    "    \"\"\"\n",
    "    Build a convolutional neural network (CNN) for glacier velocity field prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    - nb_inputs: Number of input channels (thk, slopsurfx, slopsurfy).\n",
    "    - nb_outputs: Number of output channels (ubar, vbar).\n",
    "    - config: Dictionary containing CNN configuration.\n",
    "    \n",
    "    Returns:\n",
    "    - A compiled Keras model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input layer\n",
    "    inputs = tf.keras.layers.Input(shape=[None, None, nb_inputs])\n",
    "\n",
    "    conv = inputs\n",
    "\n",
    "    # Activation function choice\n",
    "    if config['activation'] == \"lrelu\":\n",
    "        activation = tf.keras.layers.LeakyReLU(alpha=0.01)\n",
    "    else:\n",
    "        activation = tf.keras.layers.ReLU()\n",
    "\n",
    "    # Stack convolutional layers\n",
    "    for i in range(config['nb_layers']):\n",
    "        conv = tf.keras.layers.Conv2D(\n",
    "            filters=config['nb_out_filter'],\n",
    "            kernel_size=(config['conv_ker_size'], config['conv_ker_size']),\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(config['regularization']),\n",
    "            padding=\"same\"\n",
    "        )(conv)\n",
    "\n",
    "        conv = activation(conv)\n",
    "\n",
    "        conv = tf.keras.layers.Dropout(config['dropout_rate'])(conv)\n",
    "\n",
    "    # Output layer with nb_outputs channels (for ubar, vbar)\n",
    "    outputs = tf.keras.layers.Conv2D(\n",
    "        filters=nb_outputs, \n",
    "        kernel_size=(1, 1), \n",
    "        activation=None\n",
    "    )(conv)\n",
    "\n",
    "    # Return the complete model\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Compile the Model\n",
    "\n",
    "# Define the number of input channels (thk, slopsurfx, slopsurfy) and output channels (ubar, vbar)\n",
    "nb_inputs = 3  # thk, slopsurfx, slopsurfy\n",
    "nb_outputs = 2  # ubar, vbar\n",
    "\n",
    "# Build the CNN model\n",
    "model = build_cnn(nb_inputs, nb_outputs, config)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mae', metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split index for 90-10 split\n",
    "split_idx = int(0.9 * inputs_scaled.shape[0])\n",
    "\n",
    "# Train-test split for inputs\n",
    "X_train = inputs_scaled[:split_idx, :, :, :]\n",
    "X_test = inputs_scaled[split_idx:, :, :, :]\n",
    "\n",
    "# Train-test split for outputs\n",
    "y_train = outputs_scaled[:split_idx, :, :, :]\n",
    "y_test = outputs_scaled[split_idx:, :, :, :]\n",
    "\n",
    "# Apply data augmentation\n",
    "X_train_aug, y_train_aug = augment_data(X_train, y_train)\n",
    "# Check shapes\n",
    "print(f\"X_train shape: {X_train_aug.shape}\")\n",
    "print(f\"y_train shape: {y_train_aug.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode: \n",
    "# Train the model\n",
    "    history = model.fit(X_train, y_train, batch_size=8, epochs=70, validation_data=(X_test, y_test))\n",
    "    # Save the trained model to a file\n",
    "    model.save('glacier_flow_model.h5')\n",
    "else:\n",
    "    model = load_model('glacier_flow_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the learning curves for training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "\n",
    "# Plot validation loss\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Learning Curve (Loss vs. Epochs)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"Lr.png\")\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot inputs, true outputs, and predicted outputs\n",
    "def plot_comparison(thk, slopesurx, slopesury, true_ubar, true_vbar, pred_ubar, pred_vbar, time_idx=0):\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(18, 18))\n",
    "\n",
    "    # Plot inputs\n",
    "    axs[0, 0].imshow(thk[time_idx, :, :], cmap='Blues')\n",
    "    axs[0, 0].set_title('Ice Thickness (thk)')\n",
    "    axs[0, 0].set_xlabel('x')\n",
    "    axs[0, 0].set_ylabel('y')\n",
    "\n",
    "    axs[0, 1].imshow(slopesurx[time_idx, :, :], cmap='RdBu')\n",
    "    axs[0, 1].set_title('Surface Slope x (slopesurx)')\n",
    "    axs[0, 1].set_xlabel('x')\n",
    "    axs[0, 1].set_ylabel('y')\n",
    "\n",
    "    axs[0, 2].imshow(slopesury[time_idx, :, :], cmap='RdBu')\n",
    "    axs[0, 2].set_title('Surface Slope y (slopesury)')\n",
    "    axs[0, 2].set_xlabel('x')\n",
    "    axs[0, 2].set_ylabel('y')\n",
    "\n",
    "    # Plot true outputs\n",
    "    axs[1, 0].imshow(true_ubar[time_idx, :, :], cmap='viridis')\n",
    "    axs[1, 0].set_title('True Velocity x (ubar)')\n",
    "    axs[1, 0].set_xlabel('x')\n",
    "    axs[1, 0].set_ylabel('y')\n",
    "\n",
    "    axs[1, 1].imshow(true_vbar[time_idx, :, :], cmap='viridis')\n",
    "    axs[1, 1].set_title('True Velocity y (vbar)')\n",
    "    axs[1, 1].set_xlabel('x')\n",
    "    axs[1, 1].set_ylabel('y')\n",
    "\n",
    "    # Plot predicted outputs\n",
    "    axs[2, 0].imshow(pred_ubar[time_idx, :, :], cmap='viridis')\n",
    "    axs[2, 0].set_title('Predicted Velocity x (ubar)')\n",
    "    axs[2, 0].set_xlabel('x')\n",
    "    axs[2, 0].set_ylabel('y')\n",
    "\n",
    "    axs[2, 1].imshow(pred_vbar[time_idx, :, :], cmap='viridis')\n",
    "    axs[2, 1].set_title('Predicted Velocity y (vbar)')\n",
    "    axs[2, 1].set_xlabel('x')\n",
    "    axs[2, 1].set_ylabel('y')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming you have a trained model and test data loaded, let's make predictions\n",
    "predicted_outputs = model.predict(X_test)\n",
    "\n",
    "# Separate predicted outputs into ubar and vbar components\n",
    "pred_ubar = predicted_outputs[..., 0]  # First channel is ubar\n",
    "pred_vbar = predicted_outputs[..., 1]  # Second channel is vbar\n",
    "\n",
    "# Call the plot function for a specific time index, e.g., 0\n",
    "time_idx = 0\n",
    "plot_comparison(X_test[..., 0], X_test[..., 1], X_test[..., 2], y_test[..., 0], y_test[..., 1], pred_ubar, pred_vbar, time_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Implementation\n",
    "\n",
    "A basic version of this model could use the following steps:\n",
    "1. **Input Variables**: The CNN takes ice thickness and surface slope gradients as inputs  $\\{ h(x,y), \\frac{\\partial s}{\\partial x},\\frac{\\partial s}{\\partial y}\\}$.\n",
    "2. **Training the Emulator**: The model is trained using a dataset generated from high-order glacier flow models.\n",
    "3. **Prediction**: Once trained, the emulator predicts the vertically averaged ice flow from the input variables **u**(u,v).\n",
    "    \n",
    " The input and output fields are 2 D grid rasters: \n",
    "\n",
    "$\n",
    "\\R^{N_x \\times N_y \\times 3} \\rightarrow \\R^{N_x \\times N_y \\times 2} ,\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hybrid model we will calculate **u**(x,y) with the emulator we trained above and plug it in the mass conservation equation to calculate the flux. \n",
    "The implementation is similar to above with some slight changes. Now we will need a `compute_divflux()` function for each itteration of the numerical scheme.\n",
    "In addition, we will need a new function (`compute_gradient_tf()`) to calculate the slope of the glacier, remember that the velocity field is mainly dependent on the slope and the thckness of the glacier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def compute_divflux(u, v, h, dx, dy):\n",
    "    \"\"\"\n",
    "    Upwind computation of the divergence of the flux: d(u h)/dx + d(v h)/dy\n",
    "    \n",
    "    Parameters:\n",
    "    - u: x-component of velocity (2D tensor).\n",
    "    - v: y-component of velocity (2D tensor).\n",
    "    - h: ice thickness (2D tensor).\n",
    "    - dx: grid spacing in the x-direction (float).\n",
    "    - dy: grid spacing in the y-direction (float).\n",
    "    \n",
    "    Returns:\n",
    "    - divflux: divergence of flux (2D tensor).\n",
    "    \"\"\"\n",
    "    # Compute u and v on the staggered grid\n",
    "    u = tf.concat([u[:, 0:1], 0.5 * (u[:, :-1] + u[:, 1:]), u[:, -1:]], 1)  # shape (ny, nx+1)\n",
    "    v = tf.concat([v[0:1, :], 0.5 * (v[:-1, :] + v[1:, :]), v[-1:, :]], 0)  # shape (ny+1, nx)\n",
    "\n",
    "    # Extend h with constant value at the domain boundaries\n",
    "    Hx = tf.pad(h, [[0, 0], [1, 1]], \"CONSTANT\")  # shape (ny, nx+2)\n",
    "    Hy = tf.pad(h, [[1, 1], [0, 0]], \"CONSTANT\")  # shape (ny+2, nx)\n",
    "\n",
    "    # Compute fluxes by selecting the upwind quantities\n",
    "    Qx = u * tf.where(u > 0, Hx[:, :-1], Hx[:, 1:])  # shape (ny, nx+1)\n",
    "    Qy = v * tf.where(v > 0, Hy[:-1, :], Hy[1:, :])  # shape (ny+1, nx)\n",
    "\n",
    "    # Compute the divergence, final shape is (ny, nx)\n",
    "    divflux = (Qx[:, 1:] - Qx[:, :-1]) / dx + (Qy[1:, :] - Qy[:-1, :]) / dy\n",
    "    return divflux\n",
    "\n",
    "\n",
    "@tf.function()\n",
    "def compute_gradient_tf(s, dx, dy):\n",
    "    \"\"\"\n",
    "    Compute spatial 2D gradient of a given field.\n",
    "    \n",
    "    Parameters:\n",
    "    - s: surface elevation (2D tensor).\n",
    "    - dx: grid spacing in the x-direction (float).\n",
    "    - dy: grid spacing in the y-direction (float).\n",
    "    \n",
    "    Returns:\n",
    "    - diffx: gradient in the x-direction (2D tensor).\n",
    "    - diffy: gradient in the y-direction (2D tensor).\n",
    "    \"\"\"\n",
    "    EX = tf.concat([1.5 * s[:, 0:1] - 0.5 * s[:, 1:2], 0.5 * s[:, :-1] + 0.5 * s[:, 1:], 1.5 * s[:, -1:] - 0.5 * s[:, -2:-1]], 1)\n",
    "    diffx = (EX[:, 1:] - EX[:, :-1]) / dx\n",
    "\n",
    "    EY = tf.concat([1.5 * s[0:1, :] - 0.5 * s[1:2, :], 0.5 * s[:-1, :] + 0.5 * s[1:, :], 1.5 * s[-1:, :] - 0.5 * s[-2:-1, :]], 0)\n",
    "    diffy = (EY[1:, :] - EY[:-1, :]) / dy\n",
    "\n",
    "    return diffx, diffy\n",
    "\n",
    "\n",
    "def apply_boundary_condition(H_ice, boundary_width=5):\n",
    "    \"\"\"\n",
    "    Apply boundary condition to the ice thickness field `H_ice`.\n",
    "    The ice thickness will linearly decrease to zero starting from `boundary_width` pixels away from the boundary.\n",
    "    \n",
    "    Parameters:\n",
    "    - H_ice: 2D numpy array representing ice thickness.\n",
    "    - boundary_width: Number of pixels from the boundary where H_ice starts to decrease.\n",
    "    \n",
    "    Returns:\n",
    "    - Modified H_ice with boundary condition applied.\n",
    "    \"\"\"\n",
    "    ny, nx = H_ice.shape  # Get the dimensions of the ice thickness field\n",
    "\n",
    "    # Create linear ramps\n",
    "    ramp = np.linspace(1, 0, boundary_width)  # Ramp that linearly decreases from 1 to 0\n",
    "\n",
    "    # Apply boundary condition to the left boundary\n",
    "    H_ice[:, :boundary_width] *= ramp[::-1]  # Decrease from boundary to 5 pixels inwards\n",
    "\n",
    "    # Apply boundary condition to the right boundary\n",
    "    H_ice[:, -boundary_width:] *= ramp  # Decrease from 5 pixels inwards to the boundary\n",
    "\n",
    "    # Apply boundary condition to the top boundary\n",
    "    H_ice[:boundary_width, :] *= ramp[::-1, np.newaxis]  # Decrease vertically from top boundary\n",
    "\n",
    "    # Apply boundary condition to the bottom boundary\n",
    "    H_ice[-boundary_width:, :] *= ramp[:, np.newaxis]  # Decrease vertically to bottom boundary\n",
    "    \n",
    "    return H_ice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical parameters\n",
    "Lx = 49700    # Domain length in x (m)\n",
    "Ly = 32300    # Domain length in y (m)\n",
    "ttot = 700   # Time limit (yr)\n",
    "grad_b = 0.001 # Mass balance gradient (no unit)\n",
    "b_max = 0.5   # Maximum precip (m/yr)\n",
    "Z_ELA = 3000  # Elevation of equilibrium line altitude (m)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialization & load data\n",
    "\n",
    "nout = 50  # Frequency of plotting\n",
    "dtmax = 1   # maximum time step\n",
    "cfl = 0.20\n",
    "dx = 100\n",
    "dy = 100  # Cell size in y\n",
    "nx=int(Lx/dx)\n",
    "ny=int(Ly/dy)\n",
    "x = np.linspace(0, Lx, nx)  # x-coordinates\n",
    "y = np.linspace(0, Ly, ny)  # y-coordinates\n",
    "\n",
    "nc_file = netCDF4.Dataset('bedrock.nc')  # Load the NetCDF file\n",
    "Z_topo = nc_file.variables['topg']  # Replace 'topg' with the appropriate v\n",
    "\n",
    "\n",
    "\n",
    "H_ice = np.zeros((ny, nx))  # Initial ice thickness\n",
    "Z_surf = Z_topo + H_ice  # Initial ice surface\n",
    "# Compute gradients of surface elevation (slopes)\n",
    "slopsurfx, slopsurfy = compute_gradient_tf(Z_surf, dx, dx)\n",
    "time = tf.cast(0.0, tf.float32)  # Initial time as float32\n",
    "dt = tf.cast(dtmax, tf.float32)  # Cast dtmax to float32e\n",
    "it = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ensure all arrays are float32\n",
    "H_ice = tf.cast(H_ice, tf.float32)\n",
    "slopsurfx = tf.cast(slopsurfx, tf.float32)\n",
    "slopsurfy = tf.cast(slopsurfy, tf.float32)\n",
    "Z_surf = tf.cast(Z_surf, tf.float32)\n",
    "Z_topo = tf.cast(Z_topo, tf.float32)\n",
    "\n",
    "#Fields need to be scaled\n",
    "\n",
    "# Loop\n",
    "while time < ttot:\n",
    "    # Update time\n",
    "    time += dt\n",
    "    it += 1\n",
    "\n",
    "    # Calculate H_avg, size (ny-1, nx-1)\n",
    "    H_avg = 0.25 * (H_ice[:-1, :-1] + H_ice[1:, 1:] + H_ice[:-1, 1:] + H_ice[1:, :-1])\n",
    "    \n",
    "    # Scale the inputs with stored scaling factors\n",
    "    H_ice_scaled = H_ice / scaling_factors[\"thk\"]\n",
    "    slopsurfx_scaled = slopsurfx / scaling_factors[\"slopsurfx\"]\n",
    "    slopsurfy_scaled = slopsurfy / scaling_factors[\"slopsurfy\"]\n",
    "\n",
    "    # Combine scaled inputs\n",
    "    input_data_scaled = np.stack([H_ice_scaled, slopsurfx_scaled, slopsurfy_scaled], axis=-1)\n",
    "    input_data_scaled = np.expand_dims(input_data_scaled, axis=0)  # Add batch dimension\n",
    "    # Step 2: Use the trained model to predict ubar (x-velocity) and vbar (y-velocity)\n",
    "    \n",
    "    ubar_vbar_pred = model.predict(input_data_scaled, verbose=0)\n",
    "    ubar = ubar_vbar_pred[0, :, :, 0] * scaling_factors[\"ubar\"] # x-component of velocity (ubar)\n",
    "    vbar = ubar_vbar_pred[0, :, :, 1] * scaling_factors[\"vbar\"] # y-component of velocity (vbar)\n",
    "\n",
    "    # Step 3: Compute maximum velocity for CFL condition\n",
    "    vel_max = max(\n",
    "        tf.math.reduce_max(tf.math.abs(ubar)),\n",
    "        tf.math.reduce_max(tf.math.abs(vbar)),\n",
    "    ).numpy()\n",
    "    \n",
    "    # Step 4: Compute time step (CFL condition)\n",
    "    dt = tf.cast(tf.minimum(cfl * dx / vel_max, dtmax), tf.float32)\n",
    "  \n",
    "    # Step 5: Update rule (diffusion): Compute the change in thickness (dH/dt)\n",
    "    dHdt = -compute_divflux(ubar, vbar, H_ice, dx, dx)\n",
    "    \n",
    "    # Update ice thickness (ensure no negative values)\n",
    "    H_ice += dt * dHdt\n",
    "\n",
    "    # Define the SMB (Surface Mass Balance)\n",
    "    b = tf.minimum(grad_b * (Z_surf - Z_ELA), b_max)\n",
    "\n",
    "    # Update rule (mass balance)\n",
    "    H_ice += dt * b\n",
    "\n",
    "    # Update rule (positive thickness)\n",
    "    H_ice = np.maximum(H_ice, 0)\n",
    "    \n",
    "    # Apply the boundary condition before the next iteration\n",
    "    H_ice = apply_boundary_condition(H_ice)\n",
    "\n",
    "    # Update surface topography\n",
    "    Z_surf = Z_topo + H_ice\n",
    "\n",
    "    # Compute gradients of surface elevation (slopes)\n",
    "    slopsurfx, slopsurfy = compute_gradient_tf(Z_surf, dx, dx)\n",
    "\n",
    "    # Update ELA after 500 years\n",
    "    if time > 500:\n",
    "        Z_ELA = 2700\n",
    "    \n",
    "   # Display\n",
    "    if it % nout == 0:\n",
    "        clear_output(wait=True)  # Clear the previous output in the notebook\n",
    "\n",
    "        plt.figure(2, figsize=(11, 4), dpi=200)\n",
    "\n",
    "        # First subplot: Ice surface\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(Z_surf, extent=[0, Lx/1000, 0, Ly/1000], cmap='terrain', origin='lower')\n",
    "        plt.colorbar(label='Elevation (m)')\n",
    "        plt.title('Ice Surface at ' + str(int(time)) + ' y')\n",
    "        plt.xlabel('Distance, km')\n",
    "        plt.ylabel('Distance, km')\n",
    "\n",
    "        # Second subplot: Ice thickness\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(np.where(H_ice > 0, H_ice, np.nan), extent=[0, Lx/1000, 0, Ly/1000], cmap='jet', origin='lower')\n",
    "        plt.colorbar(label='Ice Thickness (m)')\n",
    "        plt.title('Ice Thickness at ' + str(int(time)) + ' y')\n",
    "        plt.xlabel('Distance, km')\n",
    "        plt.ylabel('Distance, km')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
